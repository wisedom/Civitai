{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试，爬取固定网页下载链接等信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IF YOU ARE NEW TO STABLE DIFFUSION OR YOU HAVE PROBLEMS WITH MY MODELS GO HERE: </strong><a href=\"https://inzaniak.github.io/guide\" rel=\"ugc\" target=\"_blank\"><strong>Guide</strong></a></p><p><strong>RIGHT NOW IMAGES METADATA ARE MISSING AS I\\'M USING COMFYUI TO SIMPLIFY THE IMAGE GENERATION. I\\'M TRYING TO FIND A WAY TO FIX THIS, IF SOMEONE KNOWS HOW TO DO IT, I\\'D LIKE TO KNOW.']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(comments)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# 全部内容保存成字典\u001b[39;00m\n\u001b[1;32m     68\u001b[0m tex\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownloadlink\u001b[39m\u001b[38;5;124m\"\u001b[39m:downloadlink,\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muploaded date\u001b[39m\u001b[38;5;124m\"\u001b[39m:uploaded[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m\"\u001b[39m:comments[\u001b[38;5;241m0\u001b[39m]}\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "T=[]           # 保存全部下载信息\n",
    "\n",
    "# Send an HTTP request to the website\n",
    "url = 'https://civitai.com/models/42374'              # 链接\n",
    "headers = {\n",
    "\"user-agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36\",\n",
    "\"cookie\": \"__Secure-next-auth.callback-url=https%3A%2F%2Fcivitai.com; __Host-next-auth.csrf-token=19a63269ab01f9b2fdf113515910e49f5848de590e88f643a5f218dfa47b79df%7C55738fc76b994da04af00dc500f69b3b669265a3a5310ed95f2d7223c24c3aa5; __stripe_mid=792923b6-7bff-4c39-a786-5560731c7604e2d71b; f_sort=Newest; __stripe_sid=6781e6d8-bf7f-4d62-b302-4fa4b864d090ef5702\",\n",
    "}              # request浏览器信息   \n",
    " \n",
    "response = requests.get(url,headers=headers)     # request\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')    \n",
    "\n",
    "# download link\n",
    "links =[]\n",
    "# download links\n",
    "for link in soup.find_all('a'):\n",
    "    href = link.get('href')\n",
    "    if href:\n",
    "        if href[1:4]==\"api\":\n",
    "            if href not in links:\n",
    "                links.append(href)\n",
    "# string webpage\n",
    "soup1=str(soup)     \n",
    "\n",
    "# links有信息则进行下一步操作，爬取下一个网页\n",
    "if links:\n",
    "    \n",
    "    # downloadlink\n",
    "    downloadlink=\"https://civitai.com\"+links[0]\n",
    "    \n",
    "    # name\n",
    "    name=re.findall(r\"mantine-Text-root mantine-Title-root mantine-g96yxx\\\">(.+?)</h1>\",soup1)\n",
    "\n",
    "    # uploaded date\n",
    "    uploaded=re.findall(r\"Uploaded</div></td><td class=\\\"mantine-1avyp1d\\\">(.+?)</td>\",soup1)\n",
    "    \n",
    "    # label\n",
    "    label=re.findall(r\"format=(.+?)\\\" type=\",soup1)\n",
    "\n",
    "    # comments\n",
    "    comments=[]\n",
    "    for link in soup.find_all('div'):\n",
    "        for linkk in soup.find_all('div'):\n",
    "            link1=str(linkk)\n",
    "            comment=re.findall(r\"<div><p>(.+?)</p></div></div></div>\",link1)\n",
    "            commentt=re.findall(r\"<div><p><strong>(.+?)</strong></p><p></p>\",link1)\n",
    "            if comment:\n",
    "                if comment[0] not in comments:\n",
    "                    comments.append(comment[0])\n",
    "            else:\n",
    "                if commentt:\n",
    "                    if commentt[0] not in comments:\n",
    "                        comments.append(commentt[0])\n",
    "                else:\n",
    "                    if comments:\n",
    "                        t=0\n",
    "                    else:\n",
    "                        comments.append(\" \")\n",
    "            \n",
    "print(comments)\n",
    "# 全部内容保存成字典\n",
    "tex={\"downloadlink\":downloadlink,\n",
    "    \"name\":name[0],\n",
    "    \"uploaded date\":uploaded[0],\n",
    "    \"comments\":comments[0]}\n",
    "\n",
    "#print(tex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://civitai.com/api/download/models/47051'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloadlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import unquote\n",
    "\n",
    "def get_file_name(url, headers):\n",
    "    filename = ''\n",
    "    if 'Content-Disposition' in headers and headers['Content-Disposition']:\n",
    "        disposition_split = headers['Content-Disposition'].split(';')\n",
    "        if len(disposition_split) > 1:\n",
    "            if disposition_split[1].strip().lower().startswith('filename='):\n",
    "                file_name = disposition_split[1].split('=')\n",
    "                if len(file_name) > 1:\n",
    "                    filename = unquote(file_name[1])\n",
    "    if not filename and os.path.basename(url):\n",
    "        filename = os.path.basename(url).split(\"?\")[0]\n",
    "    if not filename:\n",
    "        return time.time()\n",
    "    return filename\n",
    "\n",
    "url='https://civitai.com/api/download/models/47051'\n",
    "get_file = requests.get(url=url, headers=headers, stream=True, allow_redirects=True, timeout=10)\n",
    "\n",
    "file_name = get_file_name(url, get_file.headers)[1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'badpaint.safetensors'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬取全网站的全部链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在爬取网页：355\n",
      "正在爬取网页：356\n",
      "正在爬取网页：357\n",
      "正在爬取网页：358\n",
      "正在爬取网页：359\n",
      "正在爬取网页：360\n",
      "正在爬取网页：361\n",
      "正在爬取网页：362\n",
      "正在爬取网页：363\n",
      "正在爬取网页：364\n",
      "正在爬取网页：365\n",
      "正在爬取网页：366\n",
      "正在爬取网页：367\n",
      "正在爬取网页：368\n",
      "正在爬取网页：369\n",
      "正在爬取网页：370\n",
      "正在爬取网页：371\n",
      "正在爬取网页：372\n",
      "正在爬取网页：373\n",
      "正在爬取网页：374\n",
      "正在爬取网页：375\n",
      "正在爬取网页：376\n",
      "正在爬取网页：377\n",
      "正在爬取网页：378\n",
      "正在爬取网页：379\n",
      "正在爬取网页：380\n",
      "正在爬取网页：381\n",
      "正在爬取网页：382\n",
      "正在爬取网页：383\n",
      "正在爬取网页：384\n",
      "正在爬取网页：385\n",
      "正在爬取网页：386\n",
      "正在爬取网页：387\n",
      "正在爬取网页：388\n",
      "正在爬取网页：389\n",
      "正在爬取网页：390\n",
      "正在爬取网页：391\n",
      "正在爬取网页：392\n",
      "正在爬取网页：393\n",
      "正在爬取网页：394\n",
      "正在爬取网页：395\n",
      "正在爬取网页：396\n",
      "正在爬取网页：397\n",
      "正在爬取网页：398\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "\n",
    "T=[]                   # 保存全部下载信息\n",
    "downloadlinks = []     # 保存全部下载链接\n",
    "names = []             # 保存全部名称\n",
    "uploadeds = []         # 保存全部上传时间\n",
    "commentss = []         # 保存全部评论\n",
    "imagelinks = []        # 保存全部图片链接\n",
    "labels = []            # 保存全部标签\n",
    "count=0\n",
    "\n",
    "for i in range(355,399):\n",
    "    # Send an HTTP request to the website\n",
    "    url = 'https://civitai.com/models/42'+str(i)\n",
    "    headers = {\n",
    "        \"user-agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36\",\n",
    "        \"cookie\": \"__Secure-next-auth.callback-url=https%3A%2F%2Fcivitai.com; __Host-next-auth.csrf-token=19a63269ab01f9b2fdf113515910e49f5848de590e88f643a5f218dfa47b79df%7C55738fc76b994da04af00dc500f69b3b669265a3a5310ed95f2d7223c24c3aa5; __stripe_mid=792923b6-7bff-4c39-a786-5560731c7604e2d71b; f_sort=Newest; __stripe_sid=6781e6d8-bf7f-4d62-b302-4fa4b864d090ef5702\",\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url,headers=headers)\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # download link\n",
    "    links =[]\n",
    "    # download links\n",
    "    for link in soup.find_all('a'):\n",
    "        href = link.get('href')\n",
    "        if href:\n",
    "            if href[1:4]==\"api\":\n",
    "                if href not in links:\n",
    "                    links.append(href)\n",
    "    # string webpage\n",
    "    soup1=str(soup)\n",
    "    count = count+1       # 连续空白网页数量\n",
    "    # links有信息则进行下一步操作，爬取下一个网页\n",
    "    if links:\n",
    "        print(\"正在爬取网页：\"+str(i))\n",
    "        count = 0        # 遇到非空白网页置计数器为0\n",
    "        # downloadlink\n",
    "        downloadlink=\"https://civitai.com\"+links[0]\n",
    "        downloadlinks.append(downloadlink)\n",
    "        \n",
    "        # name\n",
    "        name=re.findall(r\"mantine-Text-root mantine-Title-root mantine-g96yxx\\\">(.+?)</h1>\",soup1)\n",
    "        names.append(name[0])\n",
    "        \n",
    "        # uploaded date\n",
    "        uploaded=re.findall(r\"Uploaded</div></td><td class=\\\"mantine-1avyp1d\\\">(.+?)</td>\",soup1)\n",
    "        uploadeds.append(uploaded[0])\n",
    "        \n",
    "        # images links\n",
    "        imagelink = []\n",
    "        for link in soup.find_all('div'):\n",
    "            #print(link)\n",
    "            link1=str(link)\n",
    "            imagesrc=re.findall(r\"src=\\\"(.+?).jpeg\",link1)\n",
    "            for i in range(0,len(imagesrc)):\n",
    "                if imagesrc[i] not in imagelink:\n",
    "                    imagelink.append(imagesrc[i]+\".jpeg\")\n",
    "        imagelinks.append(imagelink)\n",
    "        \n",
    "        # label\n",
    "        label=re.findall(r\"format=(.+?)\\\" type=\",soup1)\n",
    "        labels.append(label[0])\n",
    "        \n",
    "        # comments\n",
    "        comments=[]\n",
    "        for link in soup.find_all('div'):\n",
    "            for linkk in soup.find_all('div'):\n",
    "                link1=str(linkk)\n",
    "                comment=re.findall(r\"<div><p>(.+?)</p></div></div></div>\",link1)\n",
    "                commentt=re.findall(r\"<div><p><strong>(.+?)</strong></p><p></p>\",link1)\n",
    "                if comment:\n",
    "                    comm=comment[0].replace(\"</p><p><br/>\", \"/\")\n",
    "                    comm=comm.replace(\"</p><p>\", \"/\")\n",
    "                    if comm not in comments:\n",
    "                        comments.append(comm)\n",
    "                if commentt:\n",
    "                    comm=commentt[0].replace(\"<strong>\", \"/\")                    \n",
    "                    if comm not in comments:\n",
    "                        comments.append(comm)\n",
    "            else:\n",
    "                comments.append(' ')\n",
    "        commentst = []\n",
    "        for k in comments:\n",
    "            if k!=' ':\n",
    "                # print(k)\n",
    "                commentst.append(k)\n",
    "        if commentst: \n",
    "            commentss.append(commentst)\n",
    "        else:\n",
    "            commentss.append(' ')\n",
    "            \n",
    "        # 全部内容保存成字典\n",
    "        tex={\"downloadlink\":downloadlinks[-1],\n",
    "             \"name\":names[-1],\n",
    "             \"uploaded date\":uploadeds[-1],\n",
    "             \"images links\":imagelinks[-1],\n",
    "             \"labels\": labels[-1],\n",
    "             \"comments\":commentss[-1]}\n",
    "        \n",
    "        # 全部信息\n",
    "        T.append(tex)\n",
    "\n",
    "#print(T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据主网页创建文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在保存Hoshino Ai的评论\n",
      "正在保存Ai Hoshino [Oshi no Ko]的评论\n",
      "正在保存BadPaint - Style的评论\n",
      "正在保存Punishing Gray Raven Luna Laurel Lora的评论\n",
      "正在保存YabaL_Mix V2的评论\n",
      "正在保存Aquariumgirl#的评论\n",
      "正在保存Yu-Gi-Oh! ティアラメンツ・シェイレーン|Tearalaments Kitkalos|珠泪哀歌族·水仙女人鱼的评论\n",
      "正在保存3D CG Style| Realistic的评论\n",
      "正在保存Yakui的评论\n",
      "正在保存Corto Heilani (Droners)的评论\n",
      "正在保存Ib イヴ - Ib的评论\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import unquote\n",
    "\n",
    "def get_file_name(url, headers):\n",
    "    filename = ''\n",
    "    if 'Content-Disposition' in headers and headers['Content-Disposition']:\n",
    "        disposition_split = headers['Content-Disposition'].split(';')\n",
    "        if len(disposition_split) > 1:\n",
    "            if disposition_split[1].strip().lower().startswith('filename='):\n",
    "                file_name = disposition_split[1].split('=')\n",
    "                if len(file_name) > 1:\n",
    "                    filename = unquote(file_name[1])\n",
    "    if not filename and os.path.basename(url):\n",
    "        filename = os.path.basename(url).split(\"?\")[0]\n",
    "    if not filename:\n",
    "        return time.time()\n",
    "    return filename\n",
    "\n",
    "# 创建并进入文件夹\n",
    "def mkdir(path):\n",
    "    folder = os.path.exists(path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "        os.chdir(path)\n",
    "    else:\n",
    "        os.chdir(path)\n",
    "\n",
    "# 保存评论为txt\n",
    "def txt(name,text):              #定义函数名\n",
    "    folder = os.path.exists(name+'.txt')\n",
    "    if not folder:\n",
    "        print(\"正在保存\"+name+\"的评论\")\n",
    "        filename = name + '.txt'    #在当前py文件所在路径下的new文件中创建txt\n",
    "        file = open(filename,'w')\n",
    "        file.write(text)        #写入内容信息\n",
    "        file.close()\n",
    "    else:\n",
    "        print(\"评论已保存！\")\n",
    "\n",
    "folders = \"/Users/py/Documents/AEssay/20230417爬虫\"      # 根目录############  需要修改\n",
    "\n",
    "os.chdir(folders)           # 进入folders文件夹\n",
    "\n",
    "rootpath = \"Civital\"\n",
    "folder = os.path.exists(folders+'/'+rootpath)\n",
    "if not folder:\n",
    "    os.makedirs(\"Civital\")\n",
    "    os.chdir(folders+'/'+rootpath)\n",
    "else:\n",
    "    os.chdir(folders+'/'+rootpath)\n",
    "\n",
    "for i in range(0,len(names)):\n",
    "    os.chdir(folders+'/'+rootpath)\n",
    "    file = names[i].split('/')[0]\n",
    "    mkdir(file)                                    #调用函数\n",
    "    txt(names[i].split('/')[0],str(commentss[i]))       #创建名称为name[i]的txt文件，内容为comments\n",
    "\n",
    "# 查看当前工作目录\n",
    "retval = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下载各网页的链接、图、评论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Hoshino Ai\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Ai Hoshino [Oshi no Ko]\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/BadPaint - Style\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Punishing Gray Raven Luna Laurel Lora\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Punishing Gray Raven Luna Laurel Lora\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Punishing Gray Raven Luna Laurel Lora\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Punishing Gray Raven Luna Laurel Lora\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Punishing Gray Raven Luna Laurel Lora\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Punishing Gray Raven Luna Laurel Lora\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Punishing Gray Raven Luna Laurel Lora\n",
      "文件已下载！保存在：/Users/py/Documents/AEssay/20230417爬虫/Civital/Punishing Gray Raven Luna Laurel Lora\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 下载文件\n",
    "def url_response(url):\n",
    "    time.sleep(3)           # 防封，暂停3秒\n",
    "    path, url, t = url\n",
    "    r = requests.get(url, stream=True)\n",
    "    path1 = retval+\"/\"+path\n",
    "    paths = retval+\"/\"+path+\"/\"+t\n",
    "    if os.path.isfile(paths):\n",
    "        print(\"文件已下载！保存在：\"+path1)\n",
    "    else:\n",
    "        print(\"正在下载\"+path1)\n",
    "        with open(paths, 'wb') as f:\n",
    "            for ch in r:\n",
    "                f.write(ch)\n",
    "os.chdir(folders+\"/Civital\")\n",
    "\n",
    "urls = []\n",
    "for i in range(0,len(downloadlinks)):\n",
    "    nm = names[i].split('/')[0]\n",
    "    t = downloadlinks[i].split('/')[-1]+\".\"+labels[i]\n",
    "    if i>0:\n",
    "        if downloadlinks[i] not in urls[-1][1]:\n",
    "            urls.append((nm,downloadlinks[i],t))\n",
    "    else:\n",
    "        urls.append((nm,downloadlinks[i],t))\n",
    "    if imagelinks[i]:\n",
    "        if len(imagelinks[i][0])>1:\n",
    "            for j in range(0,len(imagelinks[i])):\n",
    "                nm = names[i].split('/')[0]\n",
    "                t = imagelinks[i][j].split('/')[-1].split('.')[0]+'.jpeg'\n",
    "                if i>0:\n",
    "                    if imagelinks[i][j] not in urls[-1][1]:\n",
    "                        urls.append((nm,imagelinks[i][j],t))\n",
    "                        #print(urls[-1])\n",
    "                    else:\n",
    "                        urls.append((nm,imagelinks[i][j],t))\n",
    "        else:\n",
    "            nm = names[i].split('/')[0]\n",
    "            t = imagelinks[i].split('/')[-1].split('.')[0]+'.jpeg'\n",
    "            if i>0:\n",
    "                if imagelinks[i][j] not in urls[-1][1]:\n",
    "                    urls.append((nm,imagelinks[i],t))\n",
    "                    #print(urls[-1])\n",
    "                else:\n",
    "                    urls.append((nm,imagelinks[i],t))\n",
    "\n",
    "start = time.time()\n",
    "ThreadPool(9).imap_unordered(url_response, urls)        # 并行下载\n",
    "\n",
    "retval = os.getcwd()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
